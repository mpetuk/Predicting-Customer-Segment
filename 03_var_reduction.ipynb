{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Read in inputs dataframe as well as weights and target series from job 02_clean_data.ipynb\n",
    "\n",
    "X = pickle.load(open(\"inputs.p\",'rb'))\n",
    "wt = pickle.load(open(\"weights.p\",'rb'))\n",
    "y = pickle.load(open(\"target.p\",'rb'))\n",
    "#y_ = pickle.load(open(\"target_.p\",'rb')) --> numeric target; unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Scale inputs so continuous variables (with higher values) don't monopolize the model \n",
    "### Also turn the result into a dataframe for easier interaction with feature importance  \n",
    "\n",
    "Xscaled= pd.DataFrame(StandardScaler().fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Rename columns back to original names instead of just index number\n",
    "old_names = Xscaled.columns\n",
    "new_names = X.columns\n",
    "Xscaled.rename(columns=dict(zip(old_names, new_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Split inputs, weights, and target into 30% test and 70% train samples, stratifying on target\n",
    "### to ensure class distribution in test and train are comparable\n",
    "\n",
    "X_train, X_test, y_train, y_test, wt_train, wt_test = train_test_split(Xscaled, y, wt,  stratify=y, test_size=.5, random_state=4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577, 493)\n",
      "(1577, 493)\n",
      "(1577,)\n",
      "(1577,)\n",
      "(1577,)\n",
      "(1577,)\n"
     ]
    }
   ],
   "source": [
    "### Check the shapes of series/dataframe\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(wt_train.shape)\n",
    "print(wt_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### sample_weight parameter in fit() call is expected in array format\n",
    "### thus, record weight series as arrays\n",
    "\n",
    "wt_train_=np.array(wt_train)\n",
    "wt_test_ =np.array(wt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pass at training a model: random forest \n",
    "#### Due to its ability to handle large number of inputs \n",
    "#### Also for ranking features by importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.981610653139\n",
      "test accuracy: 0.204185161699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 1000)\n",
    "rfc.fit(X_train, y_train, sample_weight=wt_train_)\n",
    "y_pred = rfc.predict(X_train)\n",
    "print('train accuracy:', metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred2 = rfc.predict(X_test)\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 98% accuracy on train and only 20% on test indicates overfit \n",
    "### Will do a grid search for max_depth parameter for RFC as well as PCA\n",
    "### But first, let's get rid off least important inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    493.000000\n",
       "mean       0.002028\n",
       "std        0.003211\n",
       "min        0.000000\n",
       "25%        0.000165\n",
       "50%        0.001065\n",
       "75%        0.002297\n",
       "max        0.021580\n",
       "Name: Importance_Score, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save feature importance from random forest results\n",
    "### Sort by importance in descending order\n",
    "rfc.fit(X_train, y_train, sample_weight=wt_train_)\n",
    "features = X_train.columns\n",
    "feature_importances = rfc.feature_importances_\n",
    "\n",
    "important_features = pd.DataFrame({'Features': features, 'Importance_Score': feature_importances})\n",
    "important_features.sort('Importance_Score', inplace=True, ascending=False)\n",
    "\n",
    "important_features.Importance_Score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001065144369470696"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features.Importance_Score.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Create a subset dataframe of more important half of the features (with importance score above median)\n",
    "imp_f = important_features.query('Importance_Score > 0.001065144369470696')\n",
    "## most important is nib7616_1 - Age (2-year increments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 2)\n"
     ]
    }
   ],
   "source": [
    "### Create series of more important features\n",
    "print(imp_f.shape)\n",
    "imp_f_ = imp_f['Features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474     nib7616_1\n",
       "479       nib8642\n",
       "490       nib9616\n",
       "473     nib7607_1\n",
       "471       nib7110\n",
       "485       nib9350\n",
       "486       nib9351\n",
       "488       nib9358\n",
       "462       nib3588\n",
       "463       nib3589\n",
       "452       nib2778\n",
       "482       nib8727\n",
       "481       nib8718\n",
       "460       nib3448\n",
       "480       nib8717\n",
       "453       nib2779\n",
       "458       nib3446\n",
       "489       nib9607\n",
       "459       nib3447\n",
       "487       nib9356\n",
       "461       nib3587\n",
       "484       nib8729\n",
       "464       nib3590\n",
       "457       nib2897\n",
       "454       nib2780\n",
       "468       nib3594\n",
       "470       nib4000\n",
       "483       nib8728\n",
       "465       nib3591\n",
       "469       nib3595\n",
       "          ...    \n",
       "76     nib7600_16\n",
       "210    nib8600_16\n",
       "100    nib8167_29\n",
       "430     nib9528_w\n",
       "219     nib8604_4\n",
       "195     nib8573_v\n",
       "103     nib8443_c\n",
       "308     nib8666_2\n",
       "165     nib8496_r\n",
       "316     nib8843_f\n",
       "422     nib9518_f\n",
       "402     nib9510_3\n",
       "434     nib9533_h\n",
       "376    nib9181_c4\n",
       "182    nib8560_10\n",
       "243     nib8605_7\n",
       "85      nib7609_1\n",
       "299     nib8648_b\n",
       "28      nib3101_a\n",
       "167     nib8505_d\n",
       "189     nib8570_f\n",
       "298     nib8648_a\n",
       "277     nib8637_3\n",
       "324     nib8844_b\n",
       "408     nib9512_1\n",
       "57     nib3102_4p\n",
       "423     nib9518_m\n",
       "175    nib8560_01\n",
       "442     nib9609_a\n",
       "193     nib8572_v\n",
       "Name: Features, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_f_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top 12 most important features:\n",
    "\n",
    "### nib7616_1 - age (100%)\n",
    "### nib8642 - Home Market Value - Estimated\n",
    "### nib9616 - age (1st individual)\n",
    "### nib7607_1 - Home Length of Residence - 100% \n",
    "### nib7110 - Economic Stability Indicator Financial\n",
    "### nib9350 - Economic Stability Indicator\n",
    "### nib9351 - UnderBanked Indicator\n",
    "### nib9358 - HeavyTransactors\n",
    "### nib3588 - Media Channel Usage - Cell Phone\n",
    "### nib3589 - Media Channel Usage - Primetime TV\n",
    "### nib2778 - Brand Name Medicine Propensity Score\n",
    "### nib8727 - TeleTrends - International Long Distance User\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577, 246)\n",
      "(1577, 246)\n"
     ]
    }
   ],
   "source": [
    "### Create new set of train and test inputs reduced to top half based on importance score from rfc\n",
    "new_X_train = X_train[imp_f_]\n",
    "print(new_X_train.shape)\n",
    "new_X_test = X_test[imp_f_]\n",
    "print(new_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Pickle test and train targets, weights, and new inputs (subset on importance) for modeling\n",
    "pickle.dump(new_X_train, open(\"new_train_inputs.p\",'wb'))\n",
    "pickle.dump(new_X_test, open(\"new_test_inputs.p\",'wb'))\n",
    "pickle.dump(y_train, open(\"y_train.p\",'wb'))\n",
    "pickle.dump(y_test, open(\"y_test.p\",'wb'))\n",
    "pickle.dump(wt_train_, open(\"wt_train_.p\",'wb'))\n",
    "pickle.dump(wt_test_, open(\"wt_test_.p\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
